{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d4d52e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import contractions\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50fe9f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('IMDB Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "716ff2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5cbf36cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81c9b03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        One of the other reviewers has mentioned that ...\n",
       "1        A wonderful little production. <br /><br />The...\n",
       "2        I thought this was a wonderful way to spend ti...\n",
       "3        Basically there's a family where a little boy ...\n",
       "4        Petter Mattei's \"Love in the Time of Money\" is...\n",
       "                               ...                        \n",
       "49995    I thought this movie did a down right good job...\n",
       "49996    Bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    I am a Catholic taught in parochial elementary...\n",
       "49998    I'm going to have to disagree with the previou...\n",
       "49999    No one expects the Star Trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1309f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess movie review text:\n",
    "    - Remove HTML tags\n",
    "    - Convert to lowercase\n",
    "    - Remove punctuation\n",
    "    - Remove extra spaces\n",
    "    - Optional: remove stopwords\n",
    "    - Optional: lemmatization\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Remove HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "    # 2. Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # 3. Remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "    # 4. Remove numbers\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "    # 5. Remove extra spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    words = text.split()\n",
    "\n",
    "    # 6. Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "\n",
    "    # 7. Lemmatization (optional)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "\n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a986bce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15992\\1341245625.py:13: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n"
     ]
    }
   ],
   "source": [
    "df['text']=df['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fda034bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one reviewer mentioned watching oz episode you...\n",
       "1        wonderful little production filming technique ...\n",
       "2        thought wonderful way spend time hot summer we...\n",
       "3        basically there family little boy jake think t...\n",
       "4        petter matteis love time money visually stunni...\n",
       "                               ...                        \n",
       "49995    thought movie right good job wasnt creative or...\n",
       "49996    bad plot bad dialogue bad acting idiotic direc...\n",
       "49997    catholic taught parochial elementary school nu...\n",
       "49998    im going disagree previous comment side maltin...\n",
       "49999    one expects star trek movie high art fan expec...\n",
       "Name: text, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f82b1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF matrix: (50000, 30000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=30000, ngram_range=(1,2))  \n",
    "X = vectorizer.fit_transform(df['review'])  # df['review'] = your reviews column\n",
    "y = df['sentiment']  # target column\n",
    "\n",
    "print(\"Shape of TF-IDF matrix:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c543d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 30000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "123bb235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<50000x30000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 11219979 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de7e1b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '000 000', ..., 'zoom', 'zorro', 'zucco'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_name=vectorizer.get_feature_names_out()\n",
    "feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5e8c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "y=le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f36d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbb0444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c6fbfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a54244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=Lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "618ff0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9091"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7e9d9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.9084 0.9048 0.901  0.9047 0.9039]\n",
      "Mean Accuracy: 0.90456\n",
      "Standard Deviation: 0.0023635566420121897\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(Lr, X, y, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean Accuracy:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44dcdb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'C': 6}\n",
      "Best CV Accuracy: 0.9099600000000001\n"
     ]
    }
   ],
   "source": [
    "params = {\"C\": [0.01, 0.1, 1,2,6,9,10]}\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=1000), params, cv=5, scoring=\"accuracy\")\n",
    "grid.fit(X, y)\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "print(\"Best CV Accuracy:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a15978e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive words: ['perfectly' 'loved this' 'definitely worth' 'beautifully' 'gem'\n",
      " 'incredible' 'loved' 'fun' 'refreshing' 'well worth' 'superb' 'enjoyable'\n",
      " 'brilliant' 'today' 'hilarious' 'amazing' 'wonderful' 'perfect'\n",
      " 'excellent' 'great']\n",
      "Top negative words: ['worst' 'awful' 'boring' 'waste' 'bad' 'poor' 'terrible' 'the worst'\n",
      " 'disappointment' 'horrible' 'disappointing' 'poorly' 'dull' 'worse'\n",
      " 'not worth' 'nothing' 'lame' 'lacks' 'forgettable' 'ridiculous']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "best_model = grid.best_estimator_  # your tuned model\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coef = best_model.coef_[0]\n",
    "\n",
    "# Top 20 positive words\n",
    "top_pos = np.argsort(coef)[-20:]\n",
    "print(\"Top positive words:\", feature_names[top_pos])\n",
    "\n",
    "# Top 20 negative words\n",
    "top_neg = np.argsort(coef)[:20]\n",
    "print(\"Top negative words:\", feature_names[top_neg])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b62d4161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      4961\n",
      "           1       0.91      0.92      0.91      5039\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "[[4492  469]\n",
      " [ 419 4620]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, C=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "653e524a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review  true_label  \\\n",
      "42989  'Major Payne' is a film about a major who make...           0   \n",
      "20634  normally i'm not the sort to be scared by horr...           0   \n",
      "22292  Simon Wests pg-13 thriller about a babysitter ...           1   \n",
      "43564  I really liked this quirky movie. The characte...           0   \n",
      "37447  I loved this movie when it first came out(but ...           0   \n",
      "23747  I saw this movie when it first came to the the...           0   \n",
      "18684  The major flaw with the film is its uninspired...           0   \n",
      "18692  A wonderful television mini-series completely ...           0   \n",
      "48415  Based on the comments made so far, everyone se...           0   \n",
      "16880  Despite some moments in heavy rain, an encount...           0   \n",
      "\n",
      "       predicted_label  predicted_prob  \n",
      "42989                1        0.995300  \n",
      "20634                1        0.993827  \n",
      "22292                0        0.993531  \n",
      "43564                1        0.982833  \n",
      "37447                1        0.980460  \n",
      "23747                1        0.978605  \n",
      "18684                1        0.978563  \n",
      "18692                1        0.978489  \n",
      "48415                1        0.976455  \n",
      "16880                1        0.973097  \n"
     ]
    }
   ],
   "source": [
    "# Split data (keep indices)\n",
    "X_train, X_test, y_train, y_test, train_idx, test_idx = train_test_split(\n",
    "    X, y, df.index, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(max_iter=1000, C=grid.best_params_[\"C\"])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)\n",
    "\n",
    "# Create misclassified DataFrame\n",
    "df_misclassified = pd.DataFrame({\n",
    "    'review': df.loc[test_idx, 'review'],   # use loc with original indices\n",
    "    'true_label': y_test,\n",
    "    'predicted_label': y_pred,\n",
    "    'predicted_prob': np.max(y_prob, axis=1)\n",
    "})\n",
    "\n",
    "# Filter misclassified\n",
    "df_misclassified = df_misclassified[df_misclassified['true_label'] != df_misclassified['predicted_label']]\n",
    "\n",
    "# Sort by confidence\n",
    "df_misclassified = df_misclassified.sort_values(by='predicted_prob', ascending=False)\n",
    "\n",
    "# Show top 10\n",
    "print(df_misclassified.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94dd2cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(875, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_misclassified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f782ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(review, model, vectorizer):\n",
    "    # Preprocess review (same as training step)\n",
    "    review_clean = preprocess_text(review)\n",
    "    \n",
    "    # Transform using the fitted TF-IDF vectorizer\n",
    "    X_vec = vectorizer.transform([review_clean])\n",
    "    \n",
    "    # Predict sentiment\n",
    "    pred = model.predict(X_vec)[0]\n",
    "    prob = model.predict_proba(X_vec).max()\n",
    "    \n",
    "    # Map prediction to label\n",
    "    sentiment = \"Positive 😀\" if pred == 1 else \"Negative 😡\"\n",
    "    \n",
    "    return {\"review\": review, \"prediction\": sentiment, \"confidence\": round(prob, 3)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95c64dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter movie review:good\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'review': 'good', 'prediction': 'Positive 😀', 'confidence': 0.974}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp=input('enter movie review:')\n",
    "predict_sentiment(temp,Lr,vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9749fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
